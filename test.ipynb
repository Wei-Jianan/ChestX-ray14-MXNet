{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T14:34:18.320126Z",
     "start_time": "2018-06-08T14:34:18.316665Z"
    }
   },
   "outputs": [],
   "source": [
    "import dataset\n",
    "\n",
    "from mxnet import autograd\n",
    "from mxnet import gluon, image, nd, init, metric\n",
    "\n",
    "import utils\n",
    "from dataset import load_data_ChestX_ray14\n",
    "from mxnet.gluon import nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T15:18:39.960662Z",
     "start_time": "2018-06-08T15:18:39.670297Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "train_iter, test_iter = load_data_ChestX_ray14(10, resize=224)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T15:18:40.589156Z",
     "start_time": "2018-06-08T15:18:40.207573Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetV1(\n",
       "  (features): HybridSequential(\n",
       "    (0): Conv2D(3 -> 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
       "    (2): Activation(relu)\n",
       "    (3): MaxPool2D(size=(3, 3), stride=(2, 2), padding=(1, 1), ceil_mode=False)\n",
       "    (4): HybridSequential(\n",
       "      (0): BottleneckV1(\n",
       "        (body): HybridSequential(\n",
       "          (0): Conv2D(64 -> 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
       "          (2): Activation(relu)\n",
       "          (3): Conv2D(64 -> 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
       "          (5): Activation(relu)\n",
       "          (6): Conv2D(64 -> 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        )\n",
       "        (downsample): HybridSequential(\n",
       "          (0): Conv2D(64 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        )\n",
       "      )\n",
       "      (1): BottleneckV1(\n",
       "        (body): HybridSequential(\n",
       "          (0): Conv2D(256 -> 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
       "          (2): Activation(relu)\n",
       "          (3): Conv2D(64 -> 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
       "          (5): Activation(relu)\n",
       "          (6): Conv2D(64 -> 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        )\n",
       "      )\n",
       "      (2): BottleneckV1(\n",
       "        (body): HybridSequential(\n",
       "          (0): Conv2D(256 -> 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
       "          (2): Activation(relu)\n",
       "          (3): Conv2D(64 -> 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
       "          (5): Activation(relu)\n",
       "          (6): Conv2D(64 -> 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): HybridSequential(\n",
       "      (0): BottleneckV1(\n",
       "        (body): HybridSequential(\n",
       "          (0): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "          (2): Activation(relu)\n",
       "          (3): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "          (5): Activation(relu)\n",
       "          (6): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "        )\n",
       "        (downsample): HybridSequential(\n",
       "          (0): Conv2D(256 -> 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "        )\n",
       "      )\n",
       "      (1): BottleneckV1(\n",
       "        (body): HybridSequential(\n",
       "          (0): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "          (2): Activation(relu)\n",
       "          (3): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "          (5): Activation(relu)\n",
       "          (6): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "        )\n",
       "      )\n",
       "      (2): BottleneckV1(\n",
       "        (body): HybridSequential(\n",
       "          (0): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "          (2): Activation(relu)\n",
       "          (3): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "          (5): Activation(relu)\n",
       "          (6): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "        )\n",
       "      )\n",
       "      (3): BottleneckV1(\n",
       "        (body): HybridSequential(\n",
       "          (0): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "          (2): Activation(relu)\n",
       "          (3): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "          (5): Activation(relu)\n",
       "          (6): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): HybridSequential(\n",
       "      (0): BottleneckV1(\n",
       "        (body): HybridSequential(\n",
       "          (0): Conv2D(512 -> 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "          (2): Activation(relu)\n",
       "          (3): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "          (5): Activation(relu)\n",
       "          (6): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        )\n",
       "        (downsample): HybridSequential(\n",
       "          (0): Conv2D(512 -> 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        )\n",
       "      )\n",
       "      (1): BottleneckV1(\n",
       "        (body): HybridSequential(\n",
       "          (0): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "          (2): Activation(relu)\n",
       "          (3): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "          (5): Activation(relu)\n",
       "          (6): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        )\n",
       "      )\n",
       "      (2): BottleneckV1(\n",
       "        (body): HybridSequential(\n",
       "          (0): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "          (2): Activation(relu)\n",
       "          (3): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "          (5): Activation(relu)\n",
       "          (6): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        )\n",
       "      )\n",
       "      (3): BottleneckV1(\n",
       "        (body): HybridSequential(\n",
       "          (0): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "          (2): Activation(relu)\n",
       "          (3): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "          (5): Activation(relu)\n",
       "          (6): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        )\n",
       "      )\n",
       "      (4): BottleneckV1(\n",
       "        (body): HybridSequential(\n",
       "          (0): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "          (2): Activation(relu)\n",
       "          (3): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "          (5): Activation(relu)\n",
       "          (6): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        )\n",
       "      )\n",
       "      (5): BottleneckV1(\n",
       "        (body): HybridSequential(\n",
       "          (0): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "          (2): Activation(relu)\n",
       "          (3): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "          (5): Activation(relu)\n",
       "          (6): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): HybridSequential(\n",
       "      (0): BottleneckV1(\n",
       "        (body): HybridSequential(\n",
       "          (0): Conv2D(1024 -> 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "          (2): Activation(relu)\n",
       "          (3): Conv2D(512 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "          (5): Activation(relu)\n",
       "          (6): Conv2D(512 -> 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
       "        )\n",
       "        (downsample): HybridSequential(\n",
       "          (0): Conv2D(1024 -> 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
       "        )\n",
       "      )\n",
       "      (1): BottleneckV1(\n",
       "        (body): HybridSequential(\n",
       "          (0): Conv2D(2048 -> 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "          (2): Activation(relu)\n",
       "          (3): Conv2D(512 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "          (5): Activation(relu)\n",
       "          (6): Conv2D(512 -> 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
       "        )\n",
       "      )\n",
       "      (2): BottleneckV1(\n",
       "        (body): HybridSequential(\n",
       "          (0): Conv2D(2048 -> 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "          (2): Activation(relu)\n",
       "          (3): Conv2D(512 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "          (5): Activation(relu)\n",
       "          (6): Conv2D(512 -> 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): GlobalAvgPool2D(size=(1, 1), stride=(1, 1), padding=(0, 0), ceil_mode=True)\n",
       "  )\n",
       "  (output): Dense(2048 -> 1000, linear)\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pretrained_net = gluon.model_zoo.vision.resnet50_v1(pretrained=True)\n",
    "temp_data = nd.random_normal(shape=(1, 4096))\n",
    "output_layer = nn.Dense(14,weight_initializer=init.Xavier()) \n",
    "output_layer.initialize()\n",
    "# output_layer(temp_data)\n",
    "output_layer\n",
    "pretrained_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T15:18:41.851142Z",
     "start_time": "2018-06-08T15:18:40.915081Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.5101531  -1.5016284   1.0051639   0.17700872 -0.8343903   0.2240259\n",
       "   0.32738596  0.48935762 -0.07724877 -1.5269042  -0.1039162   0.29450077\n",
       "  -1.9516547  -0.32050657]\n",
       " [ 0.47053233 -1.4301226   1.028998    0.38350764 -0.99027884  0.17465699\n",
       "   0.29515564  0.3994007   0.10518025 -1.3374596   0.00611044  0.17048465\n",
       "  -1.9130688  -0.35607213]\n",
       " [ 0.65173924 -1.2484541   0.9028948   0.28644893 -1.0224499   0.03781413\n",
       "   0.22287513  0.29557493  0.00702708 -1.5176992   0.04087946  0.28199685\n",
       "  -1.8724945  -0.52502143]\n",
       " [ 0.3611023  -1.4016876   0.9190018   0.4726807  -1.111224    0.25888544\n",
       "   0.47700617  0.39937437  0.1152609  -1.4652498  -0.15651976  0.44314834\n",
       "  -1.8407826  -0.53066623]\n",
       " [ 0.5721691  -1.2066072   0.90031594  0.2753147  -1.2124552  -0.10998757\n",
       "   0.05838182  0.38250345  0.2021772  -1.380657    0.29363713  0.3601156\n",
       "  -1.7600687  -0.34499645]]\n",
       "<NDArray 5x14 @cpu(0)>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning_net = nn.Sequential()\n",
    "tuning_net.add(pretrained_net.features,\n",
    "               output_layer)\n",
    "tuning_net\n",
    "\n",
    "temp_data = nd.random_normal(shape=(5, 3, 224, 224))\n",
    "tuning_net(temp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T15:40:08.908304Z",
     "start_time": "2018-06-08T15:40:08.896516Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = gluon.loss.SoftmaxCrossEntropyLoss(sparse_label=False)\n",
    "\n",
    "def timeit(fn):\n",
    "    import time\n",
    "    def decorator(*a, **b):\n",
    "        start = time.time()\n",
    "        fn(*a, **b)\n",
    "        end = time.time()\n",
    "        print(fn.__name__, 'take:', end - start, 's')\n",
    "    return decorator\n",
    "    \n",
    "def evaluate(data_iter, net):\n",
    "    if isinstance(data_iter, mx.io.MXDataIter):\n",
    "        data_iter.reset()\n",
    "    for X, y  in data_iter:\n",
    "        output = net(X)\n",
    "        loss = loss_fn(output, y)\n",
    "    return loss.mean().asscalar() / len(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T15:40:08.758522Z",
     "start_time": "2018-06-08T15:18:45.265188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoths 0 th:\n",
      "(32, 3, 224, 224)\n",
      "(32, 3, 224, 224)\n",
      "(19, 3, 224, 224)\n",
      "epoch 0, loss 0.3961,  test acc 1.706\n",
      "epoths 1 th:\n",
      "(32, 3, 224, 224)\n",
      "(32, 3, 224, 224)\n",
      "(19, 3, 224, 224)\n",
      "epoch 1, loss 0.2701,  test acc 1.650\n",
      "epoths 2 th:\n",
      "(32, 3, 224, 224)\n",
      "(32, 3, 224, 224)\n",
      "(19, 3, 224, 224)\n",
      "epoch 2, loss 0.2374,  test acc 1.523\n",
      "epoths 3 th:\n",
      "(32, 3, 224, 224)\n",
      "(32, 3, 224, 224)\n",
      "(19, 3, 224, 224)\n",
      "epoch 3, loss 0.1735,  test acc 1.532\n",
      "epoths 4 th:\n",
      "(32, 3, 224, 224)\n",
      "(32, 3, 224, 224)\n",
      "(19, 3, 224, 224)\n",
      "epoch 4, loss 0.1446,  test acc 1.530\n",
      "epoths 5 th:\n",
      "(32, 3, 224, 224)\n",
      "(32, 3, 224, 224)\n",
      "(19, 3, 224, 224)\n",
      "epoch 5, loss 0.1292,  test acc 1.432\n",
      "epoths 6 th:\n",
      "(32, 3, 224, 224)\n",
      "(32, 3, 224, 224)\n",
      "(19, 3, 224, 224)\n",
      "epoch 6, loss 0.1171,  test acc 1.471\n",
      "epoths 7 th:\n",
      "(32, 3, 224, 224)\n",
      "(32, 3, 224, 224)\n",
      "(19, 3, 224, 224)\n",
      "epoch 7, loss 0.1112,  test acc 1.370\n",
      "epoths 8 th:\n",
      "(32, 3, 224, 224)\n",
      "(32, 3, 224, 224)\n",
      "(19, 3, 224, 224)\n",
      "epoch 8, loss 0.1128,  test acc 1.320\n",
      "epoths 9 th:\n",
      "(32, 3, 224, 224)\n",
      "(32, 3, 224, 224)\n",
      "(19, 3, 224, 224)\n",
      "epoch 9, loss 0.1126,  test acc 1.387\n",
      "epoths 10 th:\n",
      "(32, 3, 224, 224)\n",
      "(32, 3, 224, 224)\n",
      "(19, 3, 224, 224)\n",
      "epoch 10, loss 0.1110,  test acc 1.274\n",
      "epoths 11 th:\n",
      "(32, 3, 224, 224)\n",
      "(32, 3, 224, 224)\n",
      "(19, 3, 224, 224)\n",
      "epoch 11, loss 0.1069,  test acc 1.231\n",
      "epoths 12 th:\n",
      "(32, 3, 224, 224)\n",
      "(32, 3, 224, 224)\n",
      "(19, 3, 224, 224)\n",
      "epoch 12, loss 0.1038,  test acc 1.355\n",
      "epoths 13 th:\n",
      "(32, 3, 224, 224)\n",
      "(32, 3, 224, 224)\n",
      "(19, 3, 224, 224)\n",
      "epoch 13, loss 0.1022,  test acc 1.143\n",
      "epoths 14 th:\n",
      "(32, 3, 224, 224)\n",
      "(32, 3, 224, 224)\n",
      "(19, 3, 224, 224)\n",
      "epoch 14, loss 0.1021,  test acc 1.166\n",
      "epoths 15 th:\n",
      "(32, 3, 224, 224)\n",
      "(32, 3, 224, 224)\n",
      "(19, 3, 224, 224)\n",
      "epoch 15, loss 0.1018,  test acc 1.132\n",
      "epoths 16 th:\n",
      "(32, 3, 224, 224)\n",
      "(32, 3, 224, 224)\n",
      "(19, 3, 224, 224)\n",
      "epoch 16, loss 0.1041,  test acc 1.070\n",
      "epoths 17 th:\n",
      "(32, 3, 224, 224)\n",
      "(32, 3, 224, 224)\n",
      "(19, 3, 224, 224)\n",
      "epoch 17, loss 0.1040,  test acc 1.174\n",
      "epoths 18 th:\n",
      "(32, 3, 224, 224)\n",
      "(32, 3, 224, 224)\n",
      "(19, 3, 224, 224)\n",
      "epoch 18, loss 0.1021,  test acc 0.977\n",
      "epoths 19 th:\n",
      "(32, 3, 224, 224)\n",
      "(32, 3, 224, 224)\n",
      "(19, 3, 224, 224)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-c8ab11565dd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtrain_loss_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuning_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     print(\"epoch %d, loss %.4f,  test acc %.3f\" \n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masscalar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1892\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current array is not a scalar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1894\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1896\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1874\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1875\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1876\u001b[0;31m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[1;32m   1877\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "from dataset import load_data_ChestX_ray14\n",
    "\n",
    "lr = 0.01\n",
    "trainer = gluon.Trainer(tuning_net.collect_params(), 'sgd', {'learning_rate': lr})\n",
    "train_iter, test_iter = load_data_ChestX_ray14(32, resize=224)\n",
    "for epoch in range(20):\n",
    "    print('epoths', epoch, 'th:')\n",
    "\n",
    "    for X, y in test_iter:\n",
    "        print(X.shape)\n",
    "        train_loss_sum = 0\n",
    "        with autograd.record():\n",
    "            output = tuning_net(X)\n",
    "            loss = loss_fn(output, y)\n",
    "        loss.backward()\n",
    "        trainer.step(32)\n",
    "        train_loss_sum += loss.mean().asscalar()\n",
    "    test_loss = evaluate(test_iter, tuning_net)\n",
    "    print(\"epoch %d, loss %.4f,  test acc %.3f\" \n",
    "              % (epoch, train_loss_sum / len(train_iter),\n",
    "                  test_loss))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T14:34:13.864034Z",
     "start_time": "2018-06-08T14:33:30.297Z"
    }
   },
   "outputs": [],
   "source": [
    "train_iter, test_iter = load_data_ChestX_ray14(4, resize=224)\n",
    "for data, label in train_iter:\n",
    "    print(tuning_net(data))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T15:17:55.427685Z",
     "start_time": "2018-06-08T15:17:55.376739Z"
    }
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import os\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import dataset\n",
    "import numpy as np\n",
    "from mxnet import nd, gluon, autograd\n",
    "\n",
    "from time import time\n",
    "\n",
    "# ROOT_PATH = os.path.dirname(os.path.realpath(__file__))\n",
    "\n",
    "\n",
    "# def download_ChestXray14(url=demo_url):\n",
    "#     file_name = 'chestX-ray14.zip'\n",
    "#     file_path = os.path.join(os.path.dirname(os.path.realpath(__file__)),\n",
    "#                              file_name)\n",
    "#     command = \"wget --no-check-certificate '\" + url + \"' -O \" + file_path\n",
    "#     os.system(\"wget --no-check-certificate 'https://docs.google.com/uc?export=download&id\"\n",
    "#               \"=12fbMgiEW0MuK85wXOWpZ4n_36llqz6Zw' -O chestX-ray14.zip\")\n",
    "#     os.system(command)\n",
    "#     return file_path\n",
    "\n",
    "def _get_batch(batch, ctx):\n",
    "    \"\"\"return features and labels on ctx\"\"\"\n",
    "    if isinstance(batch, mx.io.DataBatch):\n",
    "        features = batch.data[0]\n",
    "        labels = batch.label[0]\n",
    "    else:\n",
    "        features, labels = batch\n",
    "    return (gluon.utils.split_and_load(features, ctx),\n",
    "            gluon.utils.split_and_load(labels, ctx),\n",
    "            features.shape[0])\n",
    "\n",
    "\n",
    "def evaluate_accuracy(data_iter, net, ctx=[mx.cpu()]):\n",
    "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
    "    if isinstance(ctx, mx.Context):\n",
    "        ctx = [ctx]\n",
    "    acc = nd.array([0])\n",
    "    n = 0\n",
    "    if isinstance(data_iter, mx.io.MXDataIter):\n",
    "        data_iter.reset()\n",
    "    for batch in data_iter:\n",
    "        features, labels, batch_size = _get_batch(batch, ctx)\n",
    "        for X, y in zip(features, labels):\n",
    "            y = y.astype('float32')\n",
    "            acc += (net(X).argmax(axis=1) == y).sum().copyto(mx.cpu())\n",
    "            n += y.size\n",
    "        acc.wait_to_read()\n",
    "    return acc.asscalar() / n\n",
    "\n",
    "\n",
    "def evaluate_AUC(data_iter, net, ctx=[mx.cpu()]):\n",
    "    if isinstance(ctx, mx.Context):\n",
    "        ctx = [ctx]\n",
    "    # TODO reset dsata_iter\n",
    "    if isinstance(data_iter, mx.io.MXDataIter):\n",
    "        print(\"yes!!!!!!!!\")\n",
    "    AUCs = np.zeros(shape=(dataset.num_labels, ))\n",
    "    n = 0\n",
    "    for batch in data_iter:\n",
    "        # ATTENTION, this only works when the batch are equally split\n",
    "        features, labels, _ = _get_batch(batch, ctx)\n",
    "        for X, y in zip(features, labels):\n",
    "            y_hat = net(X)\n",
    "            y_hat = y_hat[:, :6]\n",
    "            print('y_hat.shape:\\t' ,y_hat.shape)\n",
    "            print(y_hat[:5])\n",
    "            y = y[:, :6]\n",
    "            print('y.shape:\\t', y.shape)\n",
    "            print(y[:, :6])\n",
    "            \n",
    "            AUC = metrics.roc_auc_score(y_true=y.asnumpy(), y_score=y_hat.asnumpy(), average=None)\n",
    "            print('AUC  :\\t', AUC)\n",
    "            AUCs += AUC\n",
    "\n",
    "            n += 1\n",
    "\n",
    "    # TODO same function with different implementation. test which one has the best perfermance.\n",
    "        # y_hats = []\n",
    "        # ys = []\n",
    "        # for X, y in zip(features, labels):\n",
    "        #     y_hats.append(net(X))\n",
    "        #     ys.append(y)\n",
    "        # nd.waitall()\n",
    "        # for y_hat, ys in zip(y_hats, ys):\n",
    "        #     AUCs += metrics.roc_auc_score(y_true=y.asnumpy(), y_score=y_hat.asnumpy(), average=None)\n",
    "\n",
    "    return AUCs / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T15:40:21.439729Z",
     "start_time": "2018-06-08T15:40:16.278038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat.shape:\t (32, 6)\n",
      "\n",
      "[[ 1.0468715   2.5704372   0.85869974  1.9694254   0.0546783  -0.40522003]\n",
      " [ 0.85632807  2.9594758   1.4306233   1.6067395  -0.17476259 -0.8086922 ]\n",
      " [ 0.22266877  2.2813516   1.7899029   1.8366884   0.28184253  0.37344462]\n",
      " [ 0.5947289   1.6204967   1.2425021   1.3474978  -0.36030486  0.29143634]\n",
      " [ 0.4341073   0.4807063   0.5747972   1.3299663   1.5840213   1.7985787 ]]\n",
      "<NDArray 5x6 @cpu(0)>\n",
      "y.shape:\t (32, 6)\n",
      "\n",
      "[[0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "<NDArray 32x6 @cpu(0)>\n",
      "AUC  :\t [1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (14,) (6,) (14,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-1e367fa981ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmxnet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mevaluate_AUC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuning_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-90-7a5203f05918>\u001b[0m in \u001b[0;36mevaluate_AUC\u001b[0;34m(data_iter, net, ctx)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mAUC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AUC  :\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAUC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mAUCs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mAUC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (14,) (6,) (14,) "
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "evaluate_AUC(test_iter, tuning_net, mx.cpu() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T14:53:14.265748Z",
     "start_time": "2018-06-08T14:53:14.253204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1  0.1  0.1  0.1  0.1 ]\n",
      " [0.4  0.4  0.4  0.4  0.4 ]\n",
      " [0.35 0.35 0.35 0.35 0.35]\n",
      " [0.8  0.8  0.8  0.8  0.8 ]]\n",
      "[[0 0 0 0 1]\n",
      " [1 1 1 0 0]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.        , 0.75      , 0.33333333])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "y_true = np.array([0, 0, 1, 1])\n",
    "ys = np.vstack([y_true  for i in range(5)])\n",
    "ys = ys.T\n",
    "\n",
    "y_scores = np.array([0.1, 0.4, 0.35, 0.8])\n",
    "y_scos = np.vstack([y_scores for i in range(5)])\n",
    "y_scos = y_scos.T\n",
    "print(y_scos)\n",
    "ys[0, 4] = 1\n",
    "ys[1, 0:3] = 1\n",
    "# ys[3,2] = 0\n",
    "print(ys)\n",
    "roc_auc_score(y_true= ys , y_score=y_scos,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T14:42:53.438065Z",
     "start_time": "2018-06-08T14:42:53.434056Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 0, 0],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
