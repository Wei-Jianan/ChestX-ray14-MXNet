{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weij\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import dataset\n",
    "import logging\n",
    "import mxnet as mx\n",
    "from mxnet import autograd\n",
    "from mxnet import gluon, image, nd, init, metric\n",
    "import model\n",
    "import utils\n",
    "from dataset import load_data_ChestX_ray14\n",
    "from mxnet.gluon import nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "num_epoches = 100\n",
    "momentum = 0.5\n",
    "ctx = utils.try_all_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, test_iter = load_data_ChestX_ray14(16, resize=224)\n",
    "\n",
    "utils.set_logging_level(level=logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_net = gluon.nn.HybridSequential()\n",
    "dense121_net = gluon.model_zoo.vision.densenet121(pretrained=True, ctx=ctx)\n",
    "output_layer = nn.Dense(14, weight_initializer=init.Xavier())\n",
    "output_layer.initialize(ctx=ctx)\n",
    "with tuning_net.name_scope():\n",
    "    tuning_net.add(dense121_net.features,\n",
    "                   output_layer)\n",
    "\n",
    "net = tuning_net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr, 'momentum': momentum})\n",
    "# loss_fn = gluon.loss.SoftmaxCrossEntropyLoss(sparse_label=False)\n",
    "loss_fn = gluon.loss.SigmoidBinaryCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55484685, 0.50194799, 0.5326838 , 0.52455076, 0.52703218,\n",
       "       0.49324393, 0.50361379, 0.52093742, 0.5931017 , 0.49582795,\n",
       "       0.49158288, 0.48221518, 0.53898346, 0.44441851])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.evaluate_AUC(test_iter, net, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  [gpu(0)]\n",
      "epoch 1, loss 0.1572, time 3621.3 sec\n",
      "train AUC:\n",
      " [0.68801702 0.56692316 0.77517799 0.61928136 0.6215412  0.57893043\n",
      " 0.60096263 0.67863215 0.70436831 0.72163507 0.63921103 0.62581466\n",
      " 0.63223255 0.55707679]\n",
      "test AUC:\n",
      " [0.63774572 0.53946641 0.7159863  0.61678987 0.58921726 0.59446969\n",
      " 0.56861382 0.67610673 0.65037965 0.6830881  0.59823752 0.66163105\n",
      " 0.63872679 0.51727777]\n",
      "epoch 2, loss 0.1503, time 3818.3 sec\n",
      "train AUC:\n",
      " [0.73865639 0.64340725 0.82955123 0.65280902 0.67756301 0.62689897\n",
      " 0.65047835 0.7318118  0.75113819 0.81892877 0.72325006 0.69131839\n",
      " 0.69019383 0.62377505]\n",
      "test AUC:\n",
      " [0.67211853 0.59168646 0.7403863  0.63386934 0.63292643 0.62204172\n",
      " 0.57356688 0.72618446 0.66916931 0.73625432 0.64958913 0.7020349\n",
      " 0.65456416 0.57192802]\n",
      "epoch 3, loss 0.1468, time 3830.8 sec\n",
      "train AUC:\n",
      " [0.75883837 0.71555465 0.84808183 0.66888503 0.69999052 0.65395809\n",
      " 0.67886626 0.75850799 0.76636687 0.84645341 0.74719861 0.71050744\n",
      " 0.71602908 0.66478013]\n",
      "test AUC:\n",
      " [0.69173201 0.63829281 0.76487155 0.64213792 0.65676757 0.6371151\n",
      " 0.5845692  0.74978808 0.66975679 0.76023845 0.67683194 0.71790725\n",
      " 0.67213762 0.58969852]\n",
      "epoch 4, loss 0.1440, time 3811.5 sec\n",
      "train AUC:\n",
      " [0.77341311 0.76890877 0.85978863 0.68331327 0.72517373 0.67987252\n",
      " 0.69092025 0.77473246 0.78047825 0.85820867 0.77374793 0.73830977\n",
      " 0.74058331 0.68841908]\n",
      "test AUC:\n",
      " [0.70361829 0.68804765 0.77348427 0.65218874 0.66912283 0.65041411\n",
      " 0.58858301 0.76192552 0.67939898 0.77138733 0.69758757 0.73512675\n",
      " 0.6825989  0.59476562]\n",
      "epoch 5, loss 0.1418, time 3787.0 sec\n",
      "train AUC:\n",
      " [0.78329025 0.79719144 0.86847939 0.69485828 0.74725877 0.69913229\n",
      " 0.69994628 0.78963974 0.78455091 0.87255378 0.79669795 0.74609607\n",
      " 0.74830888 0.71856555]\n",
      "test AUC:\n",
      " [0.7071006  0.71085812 0.78068354 0.64668554 0.68521931 0.65685405\n",
      " 0.59872598 0.77725051 0.68550797 0.78270494 0.71626603 0.73134147\n",
      " 0.68503538 0.66296619]\n",
      "epoch 6, loss 0.1400, time 3801.2 sec\n",
      "train AUC:\n",
      " [0.79046377 0.82213405 0.87101446 0.70541618 0.75984417 0.7106649\n",
      " 0.71170339 0.80381512 0.79275264 0.87810853 0.81093537 0.76040774\n",
      " 0.76242398 0.74523689]\n",
      "test AUC:\n",
      " [0.71373515 0.73692044 0.78488452 0.65600907 0.69422535 0.66700585\n",
      " 0.60494735 0.78602703 0.68483622 0.78812813 0.74004565 0.73867786\n",
      " 0.69077648 0.68754387]\n",
      "epoch 7, loss 0.1384, time 3796.8 sec\n",
      "train AUC:\n",
      " [0.79641148 0.83861469 0.87788514 0.71186657 0.7745109  0.72209639\n",
      " 0.71884401 0.81207871 0.79741987 0.88435628 0.82481103 0.76945008\n",
      " 0.76989034 0.76477317]\n",
      "test AUC:\n",
      " [0.71737677 0.75472245 0.78969529 0.65767503 0.70158888 0.66923442\n",
      " 0.61154715 0.79268008 0.6872157  0.79268306 0.75557031 0.74035209\n",
      " 0.69793539 0.72261904]\n",
      "epoch 8, loss 0.1369, time 3714.0 sec\n",
      "train AUC:\n",
      " [0.80301006 0.85250801 0.88166195 0.71857346 0.78609018 0.73115392\n",
      " 0.72505656 0.8215722  0.80575596 0.88846734 0.83749496 0.78404532\n",
      " 0.78288231 0.78005083]\n",
      "test AUC:\n",
      " [0.71913723 0.76850877 0.7917435  0.65956003 0.7109686  0.67389328\n",
      " 0.61647115 0.79903415 0.69027141 0.79736583 0.76787901 0.74057913\n",
      " 0.70318502 0.7348942 ]\n",
      "epoch 9, loss 0.1353, time 3807.9 sec\n",
      "train AUC:\n",
      " [0.8103549  0.86499859 0.88573053 0.7256819  0.79595586 0.74018107\n",
      " 0.74371009 0.83187624 0.81089924 0.89788674 0.85023776 0.78283855\n",
      " 0.78981866 0.78990383]\n",
      "test AUC:\n",
      " [0.72289353 0.78977134 0.79394704 0.66172663 0.71509206 0.67479813\n",
      " 0.61971236 0.80392344 0.69540453 0.80269525 0.77950964 0.74307867\n",
      " 0.70635018 0.7487914 ]\n",
      "epoch 10, loss 0.1340, time 3781.5 sec\n",
      "train AUC:\n",
      " [0.81336454 0.87346106 0.88945465 0.73455353 0.80694758 0.74809143\n",
      " 0.74752242 0.83871368 0.81369839 0.89766113 0.85641514 0.79147787\n",
      " 0.79617203 0.80642185]\n",
      "test AUC:\n",
      " [0.7213066  0.7994797  0.79614033 0.65991503 0.72076816 0.67776038\n",
      " 0.63109736 0.80705462 0.696639   0.80308652 0.7847303  0.74383462\n",
      " 0.70690255 0.74676233]\n",
      "epoch 11, loss 0.1326, time 3841.3 sec\n",
      "train AUC:\n",
      " [0.81925506 0.88381504 0.89386243 0.74074423 0.81534405 0.75561389\n",
      " 0.75980289 0.84775384 0.81617137 0.90320056 0.86460528 0.79842054\n",
      " 0.80492953 0.81562718]\n",
      "test AUC:\n",
      " [0.72578471 0.81000847 0.79760271 0.66168036 0.7278468  0.6773757\n",
      " 0.63065981 0.80943116 0.69903708 0.80675414 0.79444121 0.74375157\n",
      " 0.71025758 0.76736346]\n",
      "epoch 12, loss 0.1314, time 3808.6 sec\n",
      "train AUC:\n",
      " [0.82416811 0.89337043 0.89556653 0.74650989 0.82149014 0.76184136\n",
      " 0.76841632 0.85212221 0.82143128 0.90689212 0.86916748 0.8017533\n",
      " 0.80719486 0.82581515]\n",
      "test AUC:\n",
      " [0.72728664 0.81200649 0.79846305 0.66091696 0.73076832 0.6780112\n",
      " 0.63565108 0.81402452 0.69708101 0.80890197 0.80470386 0.74357332\n",
      " 0.71244327 0.78339684]\n",
      "epoch 13, loss 0.1302, time 3783.2 sec\n",
      "train AUC:\n",
      " [0.82740651 0.89585826 0.89831701 0.75067801 0.82795476 0.76973059\n",
      " 0.77573776 0.85879903 0.82529267 0.90836751 0.87838325 0.81105718\n",
      " 0.81639285 0.83609684]\n",
      "test AUC:\n",
      " [0.72487679 0.81817361 0.80024294 0.66460244 0.73555173 0.68143715\n",
      " 0.64185705 0.81594109 0.70034368 0.80902903 0.80732438 0.74672726\n",
      " 0.71334358 0.78237536]\n",
      "epoch 14, loss 0.1288, time 3849.4 sec\n",
      "train AUC:\n",
      " [0.83360661 0.90226739 0.90264065 0.75963066 0.83459512 0.77814586\n",
      " 0.77756011 0.8641333  0.83036109 0.91320498 0.88470755 0.81645898\n",
      " 0.82122844 0.84319409]\n",
      "test AUC:\n",
      " [0.72667792 0.81889934 0.79942429 0.6599134  0.73698684 0.68178123\n",
      " 0.64853338 0.81569827 0.69798238 0.80919611 0.80998624 0.74460219\n",
      " 0.71322548 0.77608644]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-78a9b7639814>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_parallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epoches\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Downloads\\ChestX-ray14-MXNet\\utils.py\u001b[0m in \u001b[0;36mtrain_parallel\u001b[1;34m(train_iter, test_iter, net, loss_fn, trainer, ctx, num_epochs, print_batches)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m             \u001b[0mtrain_loss_sum\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[0mnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Downloads\\ChestX-ray14-MXNet\\utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m             \u001b[0mtrain_loss_sum\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[0mnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mxnet\\ndarray\\ndarray.py\u001b[0m in \u001b[0;36masscalar\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1892\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The current array is not a scalar\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1894\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1895\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1896\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mxnet\\ndarray\\ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1874\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1875\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1876\u001b[1;33m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[0;32m   1877\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1878\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "utils.train_parallel(train_iter, test_iter, net, loss_fn, trainer, ctx, num_epochs=10 )\n",
    "net.save_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.save_params(str(14)+'denset121_07.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  [gpu(0)]\n",
      "epoch 1, loss 0.1275, time 3787.7 sec\n",
      "train AUC:\n",
      " [0.83851758 0.90801938 0.9051784  0.76440276 0.84390292 0.78713474\n",
      " 0.78517867 0.87056704 0.83624014 0.91526765 0.88814279 0.82389948\n",
      " 0.82619135 0.85424683]\n",
      "test AUC:\n",
      " [0.72620108 0.8244222  0.79944755 0.66300784 0.73641503 0.68369942\n",
      " 0.6434441  0.81908407 0.69971467 0.81272664 0.82063697 0.74785677\n",
      " 0.71591487 0.78071595]\n"
     ]
    }
   ],
   "source": [
    "utils.train_parallel(train_iter, test_iter, net, loss_fn, trainer, ctx, num_epochs=10 )\n",
    "net.save_params(str(24)+'denset121_07.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.train_parallel(train_iter, test_iter, net, loss_fn, trainer, ctx, num_epochs=10 )\n",
    "net.save_params(str(34)+'denset121_07.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.train_parallel(train_iter, test_iter, net, loss_fn, trainer, ctx, num_epochs=10 )\n",
    "net.save_params(str(44)+'denset121_07.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
